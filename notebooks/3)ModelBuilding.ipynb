{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.9.12)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, recall_score, \n",
    "                             roc_auc_score, roc_curve, classification_report, precision_score,f1_score,\n",
    "                             ConfusionMatrixDisplay, RocCurveDisplay)\n",
    "df = pd.read_csv('data/train.csv').drop(columns='id', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import (OneHotEncoder,StandardScaler, OrdinalEncoder, LabelEncoder)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "numerical_columns   = [col for col in df.columns if df[col].dtype!='O']\n",
    "categorical_columns = [col for col in df.columns if df[col].dtype=='O']\n",
    "\n",
    "categorical_columns_ = [i for i in categorical_columns if i not in \"NObeyesdad\"]\n",
    "output_columns =   [i for i in categorical_columns if i  in \"NObeyesdad\"]\n",
    "\n",
    "df[\"NObeyesdad\"] = label_encoder.fit_transform(df[\"NObeyesdad\"])\n",
    "\n",
    "\n",
    "independent_column = df.iloc[:,:-1]\n",
    "# dependent_column   = df.iloc[:,-1]\n",
    "dependent_column = df[output_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(independent_column.head(1),\n",
    "        dependent_column.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import (OneHotEncoder,StandardScaler, OrdinalEncoder, LabelEncoder)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer      = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "ordinal_encoder    =  OrdinalEncoder(handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"OneHotEncoder\",  oh_transformer, categorical_columns_),\n",
    "    (\"StandardScaler\", numeric_transformer, numerical_columns)    \n",
    "     ])\n",
    "independent_column = preprocessor.fit_transform(independent_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([pd.DataFrame(independent_column), dependent_column], axis=1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = final_df.iloc[:,:-1]  ## Taking all column all row except  last one(ie -1)\n",
    "y = final_df.iloc[:,-1]   ## Taking all row of the last column\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.23, random_state=42)\n",
    "print(\"-\"*79)\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"x_test shape\", x_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import(RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier)\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "print(pd.__version__) ## iteritems was removed in pandas 2.0 - try using pandas version 1.5.3 instead.\n",
    "## Or you can use this \n",
    "pd.DataFrame.iteritems = pd.DataFrame.items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    AccuracyScore = accuracy_score(true, predicted)\n",
    "    PrecisionScore = precision_score(true, predicted, average='micro')\n",
    "    RecallScore   =  recall_score(true, predicted, average='micro')\n",
    "    F1Score   =     f1_score(true, predicted, average='micro')\n",
    "    return(AccuracyScore, PrecisionScore, RecallScore, F1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Filter warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(multi_class='multinomial'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, learning_rate=0.1, loss_function='MultiClass'),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"K-Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "accuracy_dictionary = {}\n",
    "\n",
    "for k,model in models.items():\n",
    "    print(\"Fitting :-->\", k, \"_Model\")\n",
    "    model.fit(x_train, y_train)\n",
    "    y_train_predict = model.predict(x_train)\n",
    "    y_test_predict  = model.predict(x_test)\n",
    "\n",
    "    ### EVALUATE TRAIN AND THE TEST MODEL \n",
    "    train_accuracy_score,train_precision_score, train_recall_score,train_f1_score  = evaluate_model(y_train, y_train_predict)\n",
    "    test_accuracy_score, test_precision_score, test_recall_score, test_f1_score  = evaluate_model(y_test,y_test_predict)\n",
    "\n",
    "    print(\"MODEL NAME :==>\", k)\n",
    "    print(\"Model Performance On The Training Set \")\n",
    "    print(\"- TRAIN ACCURACY SCORE :->\", train_accuracy_score)\n",
    "    print(\"- TRAIN PPRECISION SCORE :->\", train_precision_score)\n",
    "    print(\"- TRAIN RECALL SCORE :->\", train_recall_score)\n",
    "    print(\"- TRAIN F1 SCORE :->\", train_f1_score)\n",
    "\n",
    "    print(\"\\n\",\"-\"*35)\n",
    "    print(\"MODEL PERFORMANCE ON THE TEST DATA :->\")\n",
    "    print(\"- TEST ACCURACY SCORE :->\", test_accuracy_score)\n",
    "    print(\"- TEST PPRECISION SCORE :->\", test_precision_score)\n",
    "    print(\"- TEST RECALL SCORE :->\", test_recall_score)\n",
    "    print(\"- TEST F1 SCORE :->\", test_f1_score)\n",
    "\n",
    "    accuracy_dictionary[k] = test_accuracy_score\n",
    "\n",
    "    print('='*65)\n",
    "    print('\\n')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(accuracy_dictionary, orient='index', columns=['Accuracy']).sort_values(by=\"Accuracy\",ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Filter warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(loss_function='MultiClass', verbose=False),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"K-Neighbors\": KNeighborsClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Quadratic Discriminant Analysis\": QuadraticDiscriminantAnalysis()\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    \"Logistic Regression\": {\"C\": [0.1, 1, 10]},\n",
    "    \"Decision Tree\": {\"max_depth\": [None, 10, 20], \"min_samples_split\": [2, 5, 10]},\n",
    "    \"Random Forest\": {\"n_estimators\": [50, 100, 150], \"max_depth\": [None, 10, 20], \"min_samples_split\": [2, 5, 10]},\n",
    "    \"Gradient Boosting\": {\"n_estimators\": [50, 100, 150], \"learning_rate\": [0.01, 0.1, 0.5]},\n",
    "    \"AdaBoost\": {\"n_estimators\": [50, 100, 150], \"learning_rate\": [0.01, 0.1, 0.5]},\n",
    "    \"CatBoost\": {\"iterations\": [50, 100, 150], \"learning_rate\": [0.01, 0.1, 0.5]},\n",
    "    \"XGBoost\": {\"n_estimators\": [50, 100, 150], \"learning_rate\": [0.01, 0.1, 0.5]},\n",
    "    \"SVM\": {\"C\": [0.1, 1, 10], \"kernel\": ['linear', 'rbf']},\n",
    "    \"K-Neighbors\": {\"n_neighbors\": [3, 5, 7], \"weights\": ['uniform', 'distance']},\n",
    "    \"Gaussian Naive Bayes\": {},\n",
    "    \"Quadratic Discriminant Analysis\": {}\n",
    "}\n",
    "\n",
    "accuracy_dictionary = {}\n",
    "\n",
    "for k, model in models.items():\n",
    "    print(\"Tuning :-->\", k)\n",
    "    random_search = RandomizedSearchCV(model, hyperparameters[k], cv=5, n_iter=10)\n",
    "    random_search.fit(x_train, y_train)\n",
    "    best_model = random_search.best_estimator_\n",
    "\n",
    "    print(\"Fitting best model on the training data...\")\n",
    "    best_model.fit(x_train, y_train)\n",
    "    y_train_predict = best_model.predict(x_train)\n",
    "    y_test_predict = best_model.predict(x_test)\n",
    "\n",
    "    train_accuracy_score, train_precision_score, train_recall_score, train_f1_score = evaluate_model(y_train,\n",
    "                                                                                                      y_train_predict)\n",
    "    test_accuracy_score, test_precision_score, test_recall_score, test_f1_score = evaluate_model(y_test,\n",
    "                                                                                                  y_test_predict)\n",
    "\n",
    "    print(\"MODEL NAME :==>\", k)\n",
    "    print(\"Model Performance On The Training Set \")\n",
    "    print(\"- TRAIN ACCURACY SCORE :->\", train_accuracy_score)\n",
    "    print(\"- TRAIN PPRECISION SCORE :->\", train_precision_score)\n",
    "    print(\"- TRAIN RECALL SCORE :->\", train_recall_score)\n",
    "    print(\"- TRAIN F1 SCORE :->\", train_f1_score)\n",
    "\n",
    "    print(\"\\n\", \"-\" * 35)\n",
    "    print(\"MODEL PERFORMANCE ON THE TEST DATA :->\")\n",
    "    print(\"- TEST ACCURACY SCORE :->\", test_accuracy_score)\n",
    "    print(\"- TEST PPRECISION SCORE :->\", test_precision_score)\n",
    "    print(\"- TEST RECALL SCORE :->\", test_recall_score)\n",
    "    print(\"- TEST F1 SCORE :->\", test_f1_score)\n",
    "\n",
    "    accuracy_dictionary[k] = test_accuracy_score\n",
    "\n",
    "    print('=' * 65)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(accuracy_dictionary, orient='index', columns=['Accuracy']).sort_values(by=\"Accuracy\",ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
